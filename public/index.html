<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head>
	<meta name="generator" content="Hugo 0.152.2"><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Shubham Apat</title>

<meta name="description" content="">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b4c2d92c2be113ac5a84dc380901003f2b5cda3766f3a1e3e17c03aa160da3b5.css" integrity="sha256-tMLZLCvhE6xahNw4CQEAPytc2jdm86Hj4XwDqhYNo7U=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/index.xml" title="rss">
<link rel="alternate" type="application/json" href="http://localhost:1313/index.json" title="json">
<link rel="alternate" hreflang="en" href="http://localhost:1313/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
</head>
<body class="list" id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Shubham Apat (Alt + H)">Shubham Apat</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/post/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/shubhamapat7" title="GitHub">
                    <span>GitHub</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<article class="first-entry home-info">
    <div class="home-info-left">
        <img loading="lazy" draggable="false" src="http://localhost:1313/images/profile2.jpg" alt="profile image" title="" height="300" width="300">
    </div>
    <div class="home-info-right">
        <div class="entry-content">
            <ul>
                <li><strong>Shubham Apat</strong> is a Data Scientist/Analyst specializing in machine learning and data analytics. Currently pursuing studies in data science and working on various ML projects.</li>
                <li>In his spare time, Shubham builds <a href="http://localhost:1313/projects/">data science projects</a>, contributes to <a href="https://github.com/shubhamapat7">open source on GitHub</a>, and writes about <a href="http://localhost:1313/post/">analytics and machine learning</a>.</li>
                <li><em>All projects and content are documented here for learning and reference. Feel free to reach out for collaborations!</em></li>
            </ul>
        </div>
        <footer class="entry-footer">
            <div class="social-icons">
                <a href="https://github.com/shubhamapat7" target="_blank" rel="noopener noreferrer me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
                </a>
                <a href="https://linkedin.com/in/shubham-apat" target="_blank" rel="noopener noreferrer me" title="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
                </a>
                <a href="mailto:shubhamapat24k@gmail.com" target="_blank" rel="noopener noreferrer me" title="Email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
    <polyline points="22,6 12,13 2,6"></polyline>
</svg>
                </a>
            </div>
        </footer>
    </div>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/university-degrees.jpg" alt="Collection of university degree certificates from around the world">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Collected 1,400 University Degrees to Build a Verification Dataset
    </h2>
  </header>
  <div class="entry-content">
    <p>The Goal Building systems for degree verification and academic fraud detection requires authentic examples. I collected degrees from LinkedIn graduation posts across 8 countries.
Coverage 1,400 unique degrees from:
USA: Ivy League, top universities, business schools India: IITs, IIMs, AIIMS UK: Oxford, Cambridge, Russell Group Australia: Group of Eight (Go8) Europe: Top institutions (ETH Zurich, TUM, etc.) Asia: NUS, NTU, Seoul National, University of Tokyo Collection Method def collect_graduation_posts(keywords, universities): posts = [] for university in universities: search_queries = [ f&#34;{university} graduation 2024&#34;, f&#34;{university} degree ceremony&#34;, f&#34;graduated from {university}&#34; ] for query in search_queries: results = linkedin_scraper.search_posts( query=query, limit=50, date_range=&#34;2023-2024&#34; ) posts.extend(results) return posts Quality Control Deduplication Used perceptual hashing to remove duplicates:
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-11-01 00:00:00 +0000 UTC'>November 1, 2024</span>&nbsp;·&nbsp;<span>2 min</span></footer>
  <a class="entry-link" aria-label="post link to I Collected 1,400 University Degrees to Build a Verification Dataset" href="http://localhost:1313/post/university-degrees-dataset/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">LinkedIn Scraper - Comprehensive Social Media Data Extraction
    </h2>
  </header>
  <div class="entry-content">
    <p>Overview Built a comprehensive LinkedIn scraping tool that can extract posts, profiles, and job listings without requiring authentication, using advanced anti-detection techniques.
Features Data Extraction Capabilities Topic-based Posts
Query any topic (e.g., “LLMs”) Configurable number of posts (e.g., 50 recent posts) Dynamic input for flexible scraping User Profiles
Complete profile information extraction Profile descriptions and details Professional history Company Profiles
Company information extraction Business details and descriptions Company posts and updates Job Listings
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-10-20 00:00:00 +0000 UTC'>October 20, 2024</span>&nbsp;·&nbsp;<span>2 min</span></footer>
  <a class="entry-link" aria-label="post link to LinkedIn Scraper - Comprehensive Social Media Data Extraction" href="http://localhost:1313/projects/linkedin-scraper/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Image Moderation using OpenAI CLIP
    </h2>
  </header>
  <div class="entry-content">
    <p>Overview Leveraged OpenAI’s CLIP (Contrastive Language-Image Pre-training) model for building an advanced image moderation pipeline with high accuracy and flexibility.
Classification System Classes NSFW SEXY NEUTRAL VIOLENCE DRUGS Methodology CLIP uses both vision and text encoders to understand images through natural language descriptions.
Approach Prompt Engineering Prompts per Class: 60&#43; text prompts per category Strategy: Diverse descriptive prompts for each class Text Encoder: CLIP’s language model generates embeddings Classification: Based on similarity scores between image and text embeddings Scoring Mechanism Similarity Calculation: Vision encoder processes input image Text Matching: Compare against all class prompts Normalization: Sigmoid function on similarity scores Classification: Highest score determines class Model Performance Optimization Techniques Grid Search CV: Systematic hyperparameter exploration Hyperparameter Tuning: Fine-tuned model parameters False Positive Analysis: Analyzed misclassifications per class Results Overall Accuracy: 92% Robust Classification: Effective across all 5 classes Generalization: Strong performance on diverse image types Advantages of CLIP Approach Flexibility: Easy to add new classes with prompts Zero-shot Learning: Can classify without class-specific training Multi-modal Understanding: Leverages both visual and textual understanding Scalable: Simple to expand classification categories Technologies Used OpenAI CLIP Computer Vision Multi-modal AI Prompt Engineering Hyperparameter Tuning Python Image Classification Natural Language Processing </p>
  </div>
  <footer class="entry-footer"><span title='2024-10-01 00:00:00 +0000 UTC'>October 1, 2024</span>&nbsp;·&nbsp;<span>1 min</span></footer>
  <a class="entry-link" aria-label="post link to Image Moderation using OpenAI CLIP" href="http://localhost:1313/projects/image-moderation-clip/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/image-dataset.jpg" alt="Large-scale image dataset collection for content moderation">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Collected 150,000&#43; Images to Train a Content Moderation Model
    </h2>
  </header>
  <div class="entry-content">
    <p>The Challenge Building a content moderation system for a social media app requires training data. Lots of it.
Dip needed to automatically detect:
NSFW content Violence Drugs Weapons Hateful content Neutral content The question: where do you get 150,000&#43; labeled images?
This was my task at ByteCitadel: collect, curate, and label a massive dataset for Dip’s image moderation pipeline.
The Plan Six categories, ~30,000 images each:
Violence (30K) Drugs (30K) NSFW (30K) Neutral (30K) Hateful Memes (30K) Weapons (30K) Total: 180,000 images (we collected extra for quality control)
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-09-15 00:00:00 +0000 UTC'>September 15, 2024</span>&nbsp;·&nbsp;<span>5 min</span></footer>
  <a class="entry-link" aria-label="post link to I Collected 150,000&#43; Images to Train a Content Moderation Model" href="http://localhost:1313/post/nsfw-moderation-dataset/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/nsfw-moderation.jpg" alt="NSFW content moderation pipeline optimization">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Made NSFW Detection 28% Faster and Beat Ultralytics&#39; Own Benchmark
    </h2>
  </header>
  <div class="entry-content">
    <p>The Problem Content moderation at scale is hard. You need to process thousands of images per second, maintain high accuracy, and do it all in &lt;200ms per image. That’s the sweet spot for “real-time” content filtering.
When I was working on the Dip social media app’s NSFW detection pipeline, we hit a bottleneck: the model was taking 250ms per image on CPU. That’s too slow for real-time use, especially when users are uploading photos rapidly.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-09-01 00:00:00 +0000 UTC'>September 1, 2024</span>&nbsp;·&nbsp;<span>5 min</span></footer>
  <a class="entry-link" aria-label="post link to I Made NSFW Detection 28% Faster and Beat Ultralytics&#39; Own Benchmark" href="http://localhost:1313/post/nsmfw-moderation-optimization/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/event-verifier.jpg" alt="Event verification system using fuzzy string matching">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Built a Bot to Catch Fake Event Listings with Fuzzy Matching
    </h2>
  </header>
  <div class="entry-content">
    <p>The Problem Event platforms like BookMyShow are full of fake listings. Users waste money on non-existent events. Platforms need automated verification.
The solution: compare claimed event details with actual page content using fuzzy string matching.
The Approach from fuzzywuzzy import fuzz def verify_event_credibility(claimed_info, actual_content): scores = {} # Compare titles title_score = fuzz.partial_ratio( claimed_info[&#39;title&#39;].lower(), actual_content[&#39;title&#39;].lower() ) # Compare descriptions desc_score = fuzz.token_sort_ratio( claimed_info[&#39;description&#39;], actual_content[&#39;description&#39;] ) # Overall credibility score overall_score = (title_score * 0.3 &#43; desc_score * 0.4 &#43; date_score * 0.2 &#43; location_score * 0.1) return { &#39;overall_score&#39;: overall_score, &#39;credible&#39;: overall_score &gt; 75 } Results 5,000 events tested 92% accuracy 70% reduction in fake event complaints Key Takeaway Simple fuzzy matching can solve complex fraud detection problems.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-08-01 00:00:00 +0000 UTC'>August 1, 2024</span>&nbsp;·&nbsp;<span>1 min</span></footer>
  <a class="entry-link" aria-label="post link to I Built a Bot to Catch Fake Event Listings with Fuzzy Matching" href="http://localhost:1313/post/event-verifier-crawler/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/property-scraper.jpg" alt="Property listing data collection from multiple platforms">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Scraped 70K Property Listings to Help Students Find Housing
    </h2>
  </header>
  <div class="entry-content">
    <p>The Mission College students in India struggle to find affordable PGs and hostels. I scraped data from three major property sites to build a comprehensive database.
The Stack class PropertyScraper: def __init__(self): self.scrapers = { &#39;magicbricks&#39;: MagicBricksScraper(), &#39;justdial&#39;: JustDialScraper(), &#39;99acres&#39;: NinetyNineAcresScraper() } Each platform needed custom scraping logic.
The Numbers Platform Properties Success Rate Magic Bricks 28,500 94% JustDial 25,000 89% 99acres 16,500 91% Total 70,000 91% Challenges Anti-bot measures: CAPTCHA, IP blocking, rate limiting Solution: Rotated user agents, added delays, proxy rotation
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-07-15 00:00:00 +0000 UTC'>July 15, 2024</span>&nbsp;·&nbsp;<span>1 min</span></footer>
  <a class="entry-link" aria-label="post link to I Scraped 70K Property Listings to Help Students Find Housing" href="http://localhost:1313/post/property-scraper-analysis/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Student ID Verification Pipeline for dip
    </h2>
  </header>
  <div class="entry-content">
    <p>Overview Built a multi-stage pipeline for verifying student ID cards using advanced deep learning models to detect various types of forgery and tampering.
Pipeline Architecture Test Dataset 97 manually collected and cleaned ID card images Diverse ID card formats and designs Model Components 1. Face Detection (YOLOv8) High-accuracy face detection in ID cards Fast inference for real-time processing 2. Gender Validation DeepFace-based gender classification Accuracy: 80% (with potential for improvement via dedicated training) 3. Splicing Detection Model: Image Splicing Detector (image_splicer_quant.tflite) Architecture: DenseNet121 with ELA preprocessing Training Data: CASIA dataset Preprocessing: Error Level Analysis (ELA) Performance: Train accuracy: 97.35% Validation accuracy: 82.31% Output: Splicing score (threshold: 0.90) Average test score: 0.95 4. Copy-Move Detection Model: New UNet (new_unet.tflite) Training: COMOFOD dataset Training: 30 epochs Accuracy: 98.7% Output: Copy-move score (threshold: 0.22) Average test score: 0.19 OCR &amp; Text Validation File: speed_uppp2.py Features: OCR text extraction Text consistency check Keyword matching (case/special character validation) Keyword match percentage calculation ELA analysis Pipeline Flow Face Detection (FaceDetection_YOLO.py) Gender Validation (gender_validation.py) Splicing Detection (splicing_detector.py) Copy-Move Detection (copymove_detector.py) OCR &amp; Text Analysis (speed_uppp2.py) Validation Results Successfully processes diverse ID card formats Robust detection of multiple forgery types Multi-layer validation ensures high accuracy Real-time processing capability Technologies Used YOLOv8 TensorFlow Lite UNet DenseNet121 DeepFace OCR (Optical Character Recognition) Error Level Analysis (ELA) Python Computer Vision </p>
  </div>
  <footer class="entry-footer"><span title='2024-06-10 00:00:00 +0000 UTC'>June 10, 2024</span>&nbsp;·&nbsp;<span>2 min</span></footer>
  <a class="entry-link" aria-label="post link to Student ID Verification Pipeline for dip" href="http://localhost:1313/projects/student-id-verification-pipeline/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">College Hotspots Dashboard - Interactive Data Visualization
    </h2>
  </header>
  <div class="entry-content">
    <p>Overview Developed an interactive data visualization dashboard from scratch to analyze student-focused businesses around colleges and universities across major Indian cities.
Dataset Source: Scraped from Google Maps Size: 3 GB of comprehensive business data Coverage: Ahmedabad, Gandhinagar, Mumbai, Pune, Kolkata, Hyderabad, Bangalore Content: All business information available on Google Maps Data Pipeline Scraping: Automated data collection from Google Maps Cleaning: Data preprocessing and validation Feature Extraction: Relevant business attributes Data Visualization: Interactive charts and maps Dashboard Features Interactive Visualizations ScatterMapBox
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-05-01 00:00:00 +0000 UTC'>May 1, 2024</span>&nbsp;·&nbsp;<span>2 min</span></footer>
  <a class="entry-link" aria-label="post link to College Hotspots Dashboard - Interactive Data Visualization" href="http://localhost:1313/projects/college-hotspots-dashboard/"></a>
</article>

<article class="post-entry"> 
<figure class="entry-cover">
        <img loading="lazy" src="http://localhost:1313/images/crocodile-research.jpg" alt="Mugger crocodile identification using UAV imagery">
</figure>
  <header class="entry-header">
    <h2 class="entry-hint-parent">I Trained a Model to Identify 160&#43; Individual Crocodiles with 98.5% Accuracy
    </h2>
  </header>
  <div class="entry-content">
    <p>The Question Can you tell crocodiles apart? Probably not—unless you’re a wildlife biologist with decades of experience.
But what if I told you that every mugger crocodile has a unique back scute pattern (like human fingerprints)? And what if we could build a computer vision model to automatically identify individual crocodiles from drone footage?
That’s exactly what I spent 6 months doing as a research intern at Ahmedabad University under Prof. Mehul Raval.
...</p>
  </div>
  <footer class="entry-footer"><span title='2024-04-20 00:00:00 +0000 UTC'>April 20, 2024</span>&nbsp;·&nbsp;<span>5 min</span></footer>
  <a class="entry-link" aria-label="post link to I Trained a Model to Identify 160&#43; Individual Crocodiles with 98.5% Accuracy" href="http://localhost:1313/post/crocodile-identification-yolov8/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="http://localhost:1313/page/2/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Shubham Apat</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
